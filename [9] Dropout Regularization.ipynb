{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.041770Z",
     "start_time": "2024-05-08T16:25:13.729733Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# import mkl\n",
    "\n",
    "# mkl.set_num_threads(2)\n",
    "np.random.seed(1234)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.047261Z",
     "start_time": "2024-05-08T16:25:14.041770Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_ones(matrix, axis=1):\n",
    "    return np.concatenate((matrix, np.ones((matrix.shape[0], 1), dtype=np.float32)), axis=axis)\n",
    "\n",
    "def zeros(*dims):\n",
    "    return np.zeros(shape=tuple(dims), dtype=np.float32)\n",
    "\n",
    "def ones(*dims):\n",
    "    return np.ones(shape=tuple(dims), dtype=np.float32)\n",
    "\n",
    "def rand(*dims):\n",
    "    return np.random.rand(*dims).astype(np.float32)\n",
    "\n",
    "def randn(*dims):\n",
    "    return np.random.randn(*dims).astype(np.float32)\n",
    "\n",
    "def chunks(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def as_matrix(vector):\n",
    "    return np.reshape(vector, (-1, 1))\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    one_hot = zeros(labels.shape[0], np.max(labels) + 1) \n",
    "    one_hot[np.arange(labels.shape[0]), labels] = 1\n",
    "    return one_hot.astype(np.float32)\n",
    "\n",
    "def classify(mlp, batch):\n",
    "    probabilities, _ = forward_pass(mlp, batch, False)\n",
    "    return np.argmax(probabilities, axis=1)\n",
    "\n",
    "def tiles(examples):\n",
    "    rows_count = examples.shape[0]\n",
    "    cols_count = examples.shape[1]\n",
    "    tile_height = examples.shape[2]\n",
    "    tile_width = examples.shape[3]\n",
    "    \n",
    "    space_between_tiles = 2\n",
    "    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,  \n",
    "                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles))\n",
    "    img_matrix.fill(np.nan)\n",
    "\n",
    "    for r in range(rows_count):\n",
    "        for c in range(cols_count):\n",
    "            x_0 = r * (tile_height + space_between_tiles)\n",
    "            y_0 = c * (tile_width + space_between_tiles)\n",
    "            ex_min = np.min(examples[r, c])\n",
    "            ex_max = np.max(examples[r, c])\n",
    "            img_matrix[x_0:x_0 + tile_height, y_0:y_0 + tile_width] = (examples[r, c] - ex_min) / (ex_max - ex_min)\n",
    "    \n",
    "    plt.matshow(img_matrix, cmap='gray', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def draw_layer_filters(layer):\n",
    "    filters = np.reshape(layer.W[:-1].T, newshape=(16, -1, 28, 28))\n",
    "    tiles(filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.050329Z",
     "start_time": "2024-05-08T16:25:14.047261Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(batch, stochastic=False):\n",
    "    activations = 1.0 / (1.0 + np.exp(-batch))\n",
    "    if stochastic:\n",
    "        return activations > rand(*activations.shape).astype(np.float32)\n",
    "    else:\n",
    "        return activations\n",
    "\n",
    "def sigmoid_derivative(batch):\n",
    "    s = sigmoid(batch)\n",
    "    return s * (1.0 - s)\n",
    "\n",
    "def softmax(batch):\n",
    "    numerator = np.exp(batch - np.max(batch, axis=1, keepdims=True))\n",
    "    denominator = np.sum(numerator, axis=1, keepdims=True)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.053406Z",
     "start_time": "2024-05-08T16:25:14.051334Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(batch, stochastic=False):\n",
    "    noise = np.random.normal(scale=np.std(batch), size=batch.shape) if stochastic else 0\n",
    "    \n",
    "    return np.maximum(0, batch + noise)\n",
    "    \n",
    "def relu_derivative(batch):\n",
    "    return np.where(batch <= 0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.320709Z",
     "start_time": "2024-05-08T16:25:14.053406Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mnist\n\u001B[0;32m      2\u001B[0m digits \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(mnist\u001B[38;5;241m.\u001B[39mtrain_images()[:\u001B[38;5;241m12\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m24\u001B[39m], newshape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m24\u001B[39m, \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m28\u001B[39m))\n\u001B[0;32m      3\u001B[0m tiles(digits)\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\__init__.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Import everything from /api/ into keras.\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__  \u001B[38;5;66;03m# Import * ignores names start with \"_\".\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Add everything in /api/ to the module search path.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\api\\__init__.py:8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\api\\activations\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deserialize\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialize\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m elu\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m exponential\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gelu\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\activations\\activations.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\__init__.py:9\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# When using the torch backend,\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# torch needs to be imported first, otherwise it will segfault\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# upon import.\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasTensor\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m any_symbolic_tensors\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_utils\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutocastScope\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasVariable\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m standardize_dtype\n\u001B[0;32m      7\u001B[0m BOOL_TYPES \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbool\u001B[39m\u001B[38;5;124m\"\u001B[39m,)\n\u001B[0;32m      8\u001B[0m INT_TYPES \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint16\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m )\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_stateless_scope\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m in_stateless_scope\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m auto_name\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mKerasVariable\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\utils\\__init__.py:12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m enable_interactive_logging\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_interactive_logging_enabled\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_visualization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m model_to_dot\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_visualization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m plot_model\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumerical_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m normalize\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\utils\\model_visualization.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tree\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m io_utils\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\tree\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m assert_same_structure\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flatten\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_nested\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optree\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dmtree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dmtree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py:17\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Register backend-specific node classes\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 17\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ListWrapper\n\u001B[0;32m     19\u001B[0m     optree\u001B[38;5;241m.\u001B[39mregister_pytree_node(\n\u001B[0;32m     20\u001B[0m         ListWrapper,\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m x: (x, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m metadata, children: ListWrapper(\u001B[38;5;28mlist\u001B[39m(children)),\n\u001B[0;32m     23\u001B[0m         namespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     24\u001B[0m     )\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_nested\u001B[39m(structure):\n",
      "File \u001B[1;32mC:\\Python\\semestr_1\\neural-networks-and-deep-learning\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdistutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_distutils\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_inspect\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "digits = np.reshape(mnist.train_images()[:12*24], newshape=(12, 24, 28, 28))\n",
    "tiles(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.321713Z",
     "start_time": "2024-05-08T16:25:14.321713Z"
    }
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, visible_size, hidden_size, activation_fun, d_activation_fun, \n",
    "                 dropout_rate, learning_rate, momentum, weight_limit):\n",
    "        self.visible_size = visible_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.activation_fun = activation_fun\n",
    "        self.d_activation_fun = d_activation_fun\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.weight_limit = weight_limit\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.W = np.random.normal(scale=0.01, size=(self.visible_size+1, self.hidden_size)).astype(np.float32)\n",
    "        self.W[-1, :] = 0.0\n",
    "        \n",
    "        self.activations = None\n",
    "        self.d_activations = None\n",
    "        self.deltas = None\n",
    "        \n",
    "        self.M = zeros(self.visible_size+1, self.hidden_size)\n",
    "        \n",
    "    def deep_copy(self):\n",
    "        copy = Layer(self.visible_size, self.hidden_size, self.activation_fun, self.d_activation_fun,\n",
    "                     self.dropout_rate, self.learning_rate, self.momentum, self.weight_limit)\n",
    "        copy.W = np.copy(self.W)\n",
    "        copy.M = np.copy(self.M)\n",
    "        return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:25:14.321713Z",
     "start_time": "2024-05-08T16:25:14.321713Z"
    }
   },
   "outputs": [],
   "source": [
    "def limit_weights(weights, limit):\n",
    "    limits = ones(*weights.shape)\n",
    "    col_norms = np.linalg.norm(weights, axis=0)\n",
    "    limits[:, col_norms > limit] = limits / col_norms[col_norms > limit]\n",
    "\n",
    "    return weights * limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "Calculate total input to the neurons. Then calculate activations (remember to add *ones* as the last column). Store result in `layer.activations`.\n",
    "\n",
    "##### Computing derivatives of activation function\n",
    "\n",
    "If `compute_derivatives` is set to `True`, we also need to compute the derivatives of the activation function and store them in `layer.d_activations`. We **do not** need to add *ones column* to the derivatives matrix! *Ones* are only needed in the activations matrix, where they are used to add biases to the total input of neurons in the next hidden layer.\n",
    "\n",
    "##### Dropout\n",
    "\n",
    "If `compute_derivatives` is set to `True` and the dropout rate in the input layer is greater than 0, we need to calculate the dropout mask for the MLP input and apply it to `batch`.\n",
    "\n",
    "When calculating hidden activations in an MLP layer, check whether dropout rate in the next layer is greater then 0. If yes, then we need to apply dropout to the calculated activations (and derivatives of activations). In this case:\n",
    "* construct dropout mask for the hidden layer,\n",
    "* apply this mask to where it is needed in the hidden layer.\n",
    "\n",
    "Do **not** apply dropout to the last column in activations or input batch, as they contains fixed *ones*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.322714Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_pass(mlp, batch, compute_derivatives):    \n",
    "    if compute_derivatives and mlp[0].dropout_rate > 0:\n",
    "        \n",
    "        batch = np.copy(batch)\n",
    "        \n",
    "        if mlp[0].dropout_rate > 0:\n",
    "            dropout_mask = rand(batch.shape[0], batch.shape[1] - 1) >= mlp[0].dropout_rate\n",
    "            batch[:, :-1] *= dropout_mask\n",
    "        \n",
    "    visible = batch\n",
    "    \n",
    "    for layer_idx, layer in enumerate(mlp):\n",
    "        z = visible @ layer.W\n",
    "        activation = layer.activation_fun(z)\n",
    "        layer.activations = append_ones(activation)\n",
    "        \n",
    "        if compute_derivatives and (layer_idx < len(mlp) - 1):\n",
    "            layer.d_activations = layer.d_activation_fun(z)\n",
    "            \n",
    "            if mlp[layer_idx+1].dropout_rate > 0:\n",
    "                dropout_mask = rand(activation.shape[0], activation.shape[1]) >= mlp[layer_idx + 1].dropout_rate\n",
    "                layer.activations[:, :-1] *= dropout_mask\n",
    "                layer.d_activations *= dropout_mask\n",
    "        \n",
    "        visible = layer.activations\n",
    "    \n",
    "    return visible[:, :-1], batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.322714Z"
    }
   },
   "outputs": [],
   "source": [
    "def error_backpropagate(mlp, batch):\n",
    "    observations_count = batch.shape[0]\n",
    "    \n",
    "    for layer_idx, layer in reversed(list(enumerate(mlp))):\n",
    "        if layer_idx > 0:\n",
    "            prev_layer = mlp[layer_idx - 1]\n",
    "            visible = prev_layer.activations\n",
    "\n",
    "            prev_layer.deltas = (layer.deltas @ layer.W[:-1].T) * prev_layer.d_activations\n",
    "        else:\n",
    "            visible = batch\n",
    "        \n",
    "        gradient = (visible.T @ layer.deltas) / observations_count\n",
    "        layer.M = layer.momentum * layer.M - layer.learning_rate * gradient\n",
    "        layer.W += layer.M\n",
    "        \n",
    "        if layer.weight_limit > 0.0:\n",
    "            layer.W[:-1, :] = limit_weights(layer.W[:-1, :], layer.weight_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean dropout network\n",
    "\n",
    "Implement the weight scalling for the network that approximates MLP outputs under dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.323713Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_network(mlp):\n",
    "    mlp = [layer.deep_copy() for layer in mlp]\n",
    "    \n",
    "    for layer in mlp:\n",
    "        layer.W[:-1, :] *= 1 - layer.dropout_rate\n",
    "    \n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.323713Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_mlp(mlp, dataset, labels, batch_size):\n",
    "    batches_limit = dataset.shape[0] / batch_size\n",
    "    \n",
    "    batched_data = chunks(dataset, batch_size)\n",
    "    batched_labels = chunks(labels, batch_size)\n",
    "    \n",
    "    for batch_idx, (batch, batch_labels) in enumerate(zip(batched_data, batched_labels)):\n",
    "        # Forward pass: compute activatations and derivatives of activations\n",
    "        y, batch_with_dropout = forward_pass(mlp, batch, True)\n",
    "\n",
    "        mlp[-1].deltas = y - batch_labels\n",
    "        \n",
    "        # Once softmax deltas are set, we may backpropagate errors\n",
    "        error_backpropagate(mlp, batch_with_dropout)\n",
    "        \n",
    "        if batch_idx % round(batches_limit / 40) == 0: print(\"#\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_mlp_training(mlp, train_set, train_labels, validation_set, validation_labels,\n",
    "                     batch_size, epochs_count):\n",
    "    for epoch in range(epochs_count):\n",
    "        print(\"Epoch {}:\".format(epoch+1),  end=\"\\t\")\n",
    "        \n",
    "        if epoch == 5:\n",
    "            for layer in mlp:\n",
    "                layer.momentum = 0.95\n",
    "                layer.learning_rate = 0.15\n",
    "        elif epoch == 150:\n",
    "            for layer in mlp:\n",
    "                layer.momentum = 0.925\n",
    "                layer.learning_rate = 0.1\n",
    "        elif epoch == 175:\n",
    "            for layer in mlp:\n",
    "                layer.momentum = 0.9\n",
    "                layer.learning_rate = 0.01\n",
    "                \n",
    "        start_time = time.time()\n",
    "        train_mlp(mlp, train_set, train_labels, batch_size)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        test_mlp = mean_network(mlp)\n",
    "        \n",
    "        predictions = classify(test_mlp, validation_set)\n",
    "        accuracy = 100.0 * np.sum(predictions == validation_labels) / predictions.shape[0]\n",
    "        print(\"\\telapsed: {0:>2.2f}s, accuracy: {1:>2.2f}\".format(elapsed, accuracy))\n",
    "\n",
    "    print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digits classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.325275Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_SIZE = 5000 # 60000 for whole dataset\n",
    "DIGIT_SIZE = 28\n",
    "\n",
    "##### Train set #####\n",
    "\n",
    "mnist_train_images = mnist.train_images().astype(np.float32) / 255.0\n",
    "mnist_train_labels = mnist.train_labels()\n",
    "\n",
    "order = np.random.permutation(len(mnist_train_images))\n",
    "mnist_train_images = mnist_train_images[order]\n",
    "mnist_train_labels = mnist_train_labels[order]\n",
    "\n",
    "mnist_train_images = np.reshape(mnist_train_images[:DATASET_SIZE],\n",
    "                                newshape=(DATASET_SIZE, DIGIT_SIZE*DIGIT_SIZE))\n",
    "mnist_train_images = append_ones(mnist_train_images)\n",
    "\n",
    "mnist_train_labels = mnist_train_labels[:DATASET_SIZE]\n",
    "mnist_train_labels = one_hot_encode(mnist_train_labels)\n",
    "\n",
    "monitoring_set_indeces = np.random.choice(mnist_train_images.shape[0], 512, replace=False)\n",
    "monitoring_set = mnist_train_images[monitoring_set_indeces]\n",
    "\n",
    "##### Test set #####\n",
    "\n",
    "mnist_test_images = mnist.test_images().astype(np.float32) / 255.0\n",
    "mnist_test_images = np.reshape(mnist_test_images, newshape=(-1, DIGIT_SIZE*DIGIT_SIZE))\n",
    "mnist_test_images = append_ones(mnist_test_images)\n",
    "\n",
    "mnist_test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.326221Z"
    }
   },
   "outputs": [],
   "source": [
    "VISIBLE_LAYER_SIZE = DIGIT_SIZE*DIGIT_SIZE\n",
    "HIDDEN_LAYER_SIZE = 1024\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS_COUNT = 200\n",
    "\n",
    "LEARNING_RATE = 0.03\n",
    "SOFTMAX_LEARNING_RATE = 0.15\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.326221Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def evaluate(mlp, train_set, train_labels,\n",
    "             validation_set, validation_labels,\n",
    "             batch_size, epochs_count):\n",
    "    for layer in mlp:\n",
    "        layer.reset()\n",
    "\n",
    "    display(HTML('<h3>MLP training</h3>'))\n",
    "    run_mlp_training(mlp,\n",
    "                     train_set, train_labels,\n",
    "                     validation_set, validation_labels,\n",
    "                     batch_size, epochs_count)\n",
    "    \n",
    "    display(HTML('<h3>Input layer filters in MLP</h3>'))\n",
    "    draw_layer_filters(mlp[0])\n",
    "    \n",
    "    display(HTML('<h3>Largest norms of weight-vectors in MLP layers</h3>'))\n",
    "    for i, layer in enumerate(mlp):\n",
    "        max_norm = np.max(np.linalg.norm(layer.W[:-1, :], axis=0))\n",
    "        print('\\tlayer {0}: {1:.2f}'.format(i+1, max_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain MLP (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.327226Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = [\n",
    "    Layer(VISIBLE_LAYER_SIZE, HIDDEN_LAYER_SIZE, relu, relu_derivative, 0.0, LEARNING_RATE, MOMENTUM,\n",
    "          weight_limit=2.0),\n",
    "    Layer(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE, relu, relu_derivative, 0.0, LEARNING_RATE, MOMENTUM,\n",
    "          weight_limit=2.0),\n",
    "    Layer(HIDDEN_LAYER_SIZE, 10, softmax, None, 0.0, SOFTMAX_LEARNING_RATE, MOMENTUM,\n",
    "          weight_limit=2.5)\n",
    "]\n",
    "\n",
    "evaluate(mlp, \n",
    "         mnist_train_images, mnist_train_labels, \n",
    "         mnist_test_images, mnist_test_labels,\n",
    "         BATCH_SIZE, EPOCHS_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-05-08T16:25:14.327226Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_with_dropout = [\n",
    "    Layer(VISIBLE_LAYER_SIZE, HIDDEN_LAYER_SIZE, relu, relu_derivative, 0.2, LEARNING_RATE, MOMENTUM,\n",
    "          weight_limit=2.0),\n",
    "    Layer(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE, relu, relu_derivative, 0.5, LEARNING_RATE, MOMENTUM,\n",
    "          weight_limit=2.0),\n",
    "    Layer(HIDDEN_LAYER_SIZE, 10, softmax, None, 0.5, SOFTMAX_LEARNING_RATE, MOMENTUM,\n",
    "          weight_limit=2.5)\n",
    "]\n",
    "\n",
    "evaluate(mlp_with_dropout, \n",
    "         mnist_train_images, mnist_train_labels, \n",
    "         mnist_test_images, mnist_test_labels,\n",
    "         BATCH_SIZE, EPOCHS_COUNT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
